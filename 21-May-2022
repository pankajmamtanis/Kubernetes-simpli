Server - Use to host/run a software / applications - request & response
software/application:piece of code
_________________________________________________________________________________________________________________
Standalone apps: desktop applications - MS-paint/notepad/calc/ms-office
A standalone application is an application that runs locally on the device and doesn't require anything else to be functional. All the logic is built into the app, so it doesn't need an internet connection nor any other services installed.

Web application: an app that can be accessed on a network (in a browser) - facebook
In computer system, a web application is a client-side and server-side software application in which the client runs or request in a web browser. Common web applications include email, online retail sales, online auctions, wikis, instant messaging services and more.
_________________________________________________________________________________________________________________
Web-server
A web server is software and hardware that uses HTTP (Hypertext Transfer Protocol) and other protocols to respond to client requests made over the World Wide Web. The main job of a web server is to display website content through storing, processing and delivering webpages to users. Besides HTTP, web servers also support SMTP (Simple Mail Transfer Protocol) and FTP (File Transfer Protocol), used for email, file transfer and storage.
EX-nginx/apache/tomcat

Run-time environment - websphere/weblogic/jboss
_________________________________________________________________________________________________________________
types of Servers - physical and VM

we have below issues to be addressed
____________________________________
maintaining physical servers in DC is expensive
resource wastage is there with physical or manage yourself case
maintenance is very high
scalability
______________________________________
using virtualisation saves a lot of resources using hardware virtualisation
_________________________________________________________________________

environment - single/group of servers (physical/virtual) where we run our software

Dev - (tomcat java) -war file deployed

QA - (tomcat java) -war file deployed

PROD - (tomcat java) -war file deployed

same war working in Dev might not work in prod due to environment different, could be reason for same code to fail in production
______________________________________________________________________________

how to build and run containers?

- we need containerization tool/software - docker/crio/containerd/lxc/rocket

image vs container 
- docker image is just software package that sits on your disk doing nothing
- 
- run time instance of an image is called container
- container is just a process that runs on your server (physical/virtual) and consume the resources like cpu & ram to process a request

- docker image is like template/blueprint from which we can run multiple containers

_________________________________________________________________________________

docker is a tool / software first released in 2013

docker is written in GoLang

docker ce - communiry edition - free
dockker ee - enterprise edition - purchased version - merantis

_____________________________________________________________________________

containers vs virtualisation 

https://www.baeldung.com/cs/virtualization-vs-containerization#:~:text=Virtualization%20and%20containerization%20are%20the,the%20concept%20of%20a%20container.
full OS vs minimal OS (OSLIB)
fat vs fit 
kernel vs no-kernel (command line missing grep yum etc)
size of image
____________________________________________________________________________________________

foreground vs background process- The foreground contains the applications the user is working on, and the background contains the applications that are behind the scenes, such as certain operating system functions, printing a document or accessing the network.

container running in detach mode - background process
container running in attach mode - foreground process

_______________________________________________________________________________________

docker pull docker.io/library/tomcat:latest
docker pull nginx
docker image ls

docker run -d centos // does not keep running as there is no process, it will exit. body will run only if heart is beating likewise process has to be running

docker inspect <>  // command running inside every container can be checked

root@ip-172-31-59-162:~# docker ps -a
CONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS                     PORTS     NAMES
9db4718e35a7   centos    "/bin/bash"              4 minutes ago   Exited (0) 4 minutes ago             nervous_haibt (bin/bash runs and exits)
aa6df4e4ff74   nginx     "/docker-entrypoint.…"   5 minutes ago   Up 5 minutes               80/tcp    focused_pike
root@ip-172-31-59-162:~# 
_________________________________________________________________________________________
root@ip-172-31-59-162:~# docker run -d centos sleep 190
0ec7044c02d9702ba1293bc9dc2294d6927d4bfa69347358b3a7f75688c96ff2
root@ip-172-31-59-162:~# docker ps
CONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS         PORTS     NAMES
0ec7044c02d9   centos    "sleep 190"              3 seconds ago   Up 2 seconds             stoic_cohen >>>>>>>>>>>>>>>> container is running till sleep is running
aa6df4e4ff74   nginx     "/docker-entrypoint.…"   6 minutes ago   Up 6 minutes   80/tcp    focused_pike
root@ip-172-31-59-162:~# 

________________________________________

every container has its own network // different iP address and ports
curl =<containerIP>:port

root@ip-172-31-59-162:~# curl 172.17.0.2:80>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
root@ip-172-31-59-162:~# 

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>.
from the host machine
root@ip-172-31-59-162:~# curl localhost:49153
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
root@ip-172-31-59-162:~# 


>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

docker port mapping with container to access docker from host machine
docker run -d -P nginx

docker run -d -P lerndevops/samples:mywebsite-v1

docker ps
hostname -i

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>.
   38  docker run -d -P lerndevops/samplesmywebsite-v1
   39  curl 72.17.0.2:49153
   40  curl 172.17.0.2:49153
   41  curl 172.17.0.2:80
   42  curl localhost:49153
   43  docker run -d -P lerndevops/samplesmywebsite-v1
   44  docker run -d -P lerndevops/samples:mywebsite-v1
   45  docker ps
   46  docker inspect 89ffb64e9fc7
   47  curl 172.17.0.4:80
   48  docker ps
   49  curl 172.31.59.162:49154
   
   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
   capital P is dynamic port numbering -- since port numbers change therefore mapping it again and again would be difficult for request routing (container to host)
   therefore we need container orchestrator
   
   K8 helps us run multiple container from multiple imagesinto multiple servers/VM..
   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>.
   
   master/manager (controls, deploys, ) -1 <<docker service create replicas 100 nginx
   
   worker/team - 2 or more
   >>>>>>>>>>>>>>>>>>>
   K8 needs one container tool to be installed - docker / crio/containerd/rocket
   K8 software needs to be installed on the Master -KUBEADM / KUBELET
   
   above 3 are needed on worker nodes too - docker / kubeadm /kubelet
   
   ----KUBEADM 
   - is a tool to init the kube master process / node
   - is a tool helps join the worker to master
   
   (kubeadm init on master {initialises master process on Master}          --- kubeadmn join on worker)
   
   application node communicating with DB node communicating each service is communicating with each other.
   
   
   ------KUBELET
   - is an agent process that runs on every node
   - it is responsible for master and worker communication
   - kubelet process starts autoMATICALLY when we run kubeadm join on worker process
   
   ---KUBECTL get nodes ( docker ps)
   -- kubectl create
   -- kubectl describe
   -- kubectl delete
   -- kubectl apply
   
   MASTER has API process which will communicate with Worker nodes.
   kubelet not needed on Master, if at all you need to run worker node on Master too.
   
   Kubernetes
   - Autoscaling yes, but docker no
   - RBAC - we can do a create read update delete seperately as needed, Docker swarn does not have( can have in purchased version)
   - SSL communication within the cluster, docker swarm does not give this for free (can be purchased)
   
   
   Docker network
   - by default its a bridge network for all to comm with all
   - docker init gets in overlay network
   
   Kubernetes 
   - by default there is no networking drivers configured in kube cluster for container communication
   - we must install networking driver as part of the cluster setup
     - calico/ canal / flannel / weave etc. 
   
   
   
   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
   
   
   https://drive.google.com/drive/folders/1BS1Oyq1Qhr5qh_BZZeTSvcd_kS5DJah9?usp=sharing  >>>>>>>>>>>Notes from the trainer
   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
   
https://github.com/lerndevops/educka/blob/master/1-intall/README.md >>>>>>>>>>>>>>>>git manual install steps to be followed.

my work done for Kubelab..

MASTER ----- all worked
Worker1 ------ kubeadm reset --force , then with join command
Worker1 ------ kubeadm reset --force , then with join command


for the lock
ps -ef |grep apt
/var/lib/dpkg/ then
rm -rf lock frontend lock

>>>>>>>>>>>>>>>>>>>>>>>>>>>
POD LIFE CYCLE
>>>>>>>>>>>>>>
kubectl run webapp --image=docker.io/lerndevops/samples:mywebsite-v1
pod/webapp created

root@ip-172-31-15-152:~# kubectl get pods -o wide
NAME     READY   STATUS              RESTARTS   AGE   IP       NODE              NOMINATED NODE   READINESS GATES
webapp   0/1     ContainerCreating   0          38s   <none>   ip-172-31-8-114   <none>           <none>
root@ip-172-31-15-152:~# 

root@ip-172-31-15-152:~# kubectl run nginxpod --image=nginx:latest
pod/nginxpod created
root@ip-172-31-15-152:~# kubectl get pods -o wide
NAME       READY   STATUS              RESTARTS   AGE    IP       NODE              NOMINATED NODE   READINESS GATES
nginxpod   0/1     ContainerCreating   0          4s     <none>   ip-172-31-3-210   <none>           <none>
webapp     0/1     ContainerCreating   0          113s   <none>   ip-172-31-8-114   <none>           <none>
root@ip-172-31-15-152:~# 

curl <IP of POD>:port ##to open the app

kubectl describe nginxpod

kubectl exec -it nginx -- /bin/bash

service nginx status // from inside of bin/bash

kubectl delete pod nginxpod
--------------------------------------------------------------------

ok. so each pod can have same image containers, only the number can be 1 or more. correct?

pods can have multple containers - of nginx container 1 or more 



__________________________________________________________________
Kubernetes PODS
-------------
Pods are the smalles deployable units of computing that you can create and manage in k8s

______________________________________________________________________
kubectl get pods -o wide --all-namespsaces

Namespaces
In Kubernetes, namespaces provides a mechanism for isolating groups of resources within a single cluster. Names of resources need to be unique within a namespace, but not across namespaces.
_____________________________________________________________________

Kubernetes Architecture

Master (can also have worker node in this)
- API Server <Master process -- Team manager finds out who can work on the request basis b/w>  (info request (kubectl get nodes) ---> goes to API server to get details and returns
- ETCD (cluster store) - DB (key value store, nodes available, status of nodes, node config, no. of processes, OS, container runtime running, how long pod is running, all cluster data)
- Scheduler (identify worker node which is free)
- controller manager

Worker (below gets added only post join command)
- kubelet (receives request from APPI server, --asks contianer to pull image -- interacts with netw
- container runtime runtime (dcker) (pulls images from docker)
- kube proxy
- networking driver (weave)


>>>>> use cases
kubectl get nodes (info request (kubectl get nodes) ---> goes to API server to get details and returns

kubectl run pod1 - image = nginx 
kubectl- API server - Scheduler - API Server - kubelet - docker & weave - kubelet - api server - ETCD

mult-master mode cluster should be there in production, 
________________________________________________

Controller manager
- is responsible for desired state
- what we request is called desired (make sure actual state reaches desired state)
- auto healing and auto-scaling

_____________
Kube-Proxy (fwds node to container & port forwarding and publishing - intermediary)
- helps to publish port for containers & updates the required routing config to route the requests to the container from the host

WORKER = NODE
________________________

big deployment we cant use command line

abc.yaml/yml - yaml aint markup lang -- data serialisation lang

there is one basic rule we need to follow while writing yaml - indentation
_________________________

===============================================
follow 3 data structures in YAML

--------scalar
name: naresh
a: 5
b : 56.6
ab: true

----- dictionary / map 
laptop:
  ram: 16gb
  cpu: 8 core
  disk: 1 tb
  model: apple
  
-------list/array
- bmw
- audi
- RR
===============================================

cars:
  - bmw
      color: red
      model: sedan
      engine: 2l
  - audi
      color: blue
      model: xuv
      enginer:3.5l
  - RR:
      color:
         - blue
         - white
         - red
       model:
        - phantom
        - ghost
       engine:
        - 3L
        - 5L
        - 6L
        
        
  ++++++++++++++++++++++++++++++++++++
  
  Keys are pre-defined by the technology (K8s - manifest, docker - compose, ansible - compose)
  
      
  ----
  kubectl run podx --image-nginx
  -----
  kubectl run podx --image-nginx --namespace=teama -l team=sysadmin
  in yaml
  
  kind: POD #### / Daemonset/Namespace/    # kubectl api-resources (all what is shown in this can be used in this as Kind)
  apiVersion : v1
  metadata: 
    name: podx
    namespace:teama ## if we dont define then detault
    label:     ##label is mandatory, if we do not define a label kube will assign one by default
      team: sysadmin # here both key and value is your choice
      teams1: systemadm1 ## label2 and value2
  spec:
     container:
      - name: cont1
        image: tomcat:label
        ports:
          - name: http
            containerPort: 8080
          - name https
            containerPort: 8443
      - name: cont2
        image: nginx
      
 ___________________
 
  apiVersion : v1
  metadata: 
    name: multi-cont-pod
    namespace:teama ## if we dont define then detault
    label:     ##label is mandatory, if we do not define a label kube will assign one by default
      team: sysadmin # here both key and value is your choice
      teams1: systemadm1 ## label2 and value2
  spec:
    restartPolicy: Always # in case of any issue with container it will restart do # Never # will not restart it
     container:    ## app container array
      - name: cont1
        image: tomcat:label
        ports:
          - name: http
            containerPort: 8080
      - name: cont2
        image: nginx:latest
        ports:
          - name: http
            containerPort: 80
      - name: cont3
        image: ubuntu:latest
        ports:
          - name: http
            containerPort: 80
            
        
      
 ___________________
 
    kubectl describe pod <multi-pod> ## dettailed logs
    kubectl logs weapp ## gets logs for container
    
    kubecctl logs multi-cont-pod-2 -cont3 ## gets cont3 logs
    kubecctl logs multi-cont-pod-2 -cont3
    
kubectl exec -it multi-cont-pod2 -c cont1 --bin/bash ## get into container-1
kubectl exec -it multi-cont-pod2 -c cont2 --bin/bash ## get into container-2 # check service nginx status

get into container while single IP is given to POD
curt 10:44.0.4:80 # for nginx access on different port for each container inside POD
curt 10:44.0.4:8080 # for nginx access on different port for each container inside POD
___________
these are cases where a different namespace is mentioned in the yaml while creating it, then we will have to mentiond the earlier mentioned namespace

kubectl --namespace default exec -it multi-cont-pod2 -c cont1 --/bin/bash ## 

________-----------------------------

Init Containers - 



  apiVersion : v1
  metadata: 
    name: multi-cont-pod
    namespace:teama ## if we dont define then detault
    label:     ##label is mandatory, if we do not define a label kube will assign one by default
      team: sysadmin # here both key and value is your choice
      teams1: systemadm1 ## label2 and value2
  spec:
    restartPolicy: Always # in case of any issue with container it will restart do # Never # will not restart it
    initContainers           ## run run to completion, does not complete by itself, to check if process exited with code 0=good <> 0 bad. check this with #echo$?
       #sleep 5
       #echo $?
       #0
       #Sleep 4
       #echo $?
       #1
       
       #previous one should complete successfully before we execute the next one
       # Use case - check if DB is up or not before we spin the containers. check by doing telnet to DB.
       # Init container will runs dependency only once, if any of the prod container crashes, there is nothing it will do with init.
       # we can put any sequencing for init containers, it will always get executed first. 
       - 
    container:    ## app container array
      - name: cont1
        image: tomcat:label
        ports:
          - name: http
            containerPort: 8080
      - name: cont2
        image: nginx:latest
        ports:
          - name: http
            containerPort: 80
      - name: cont3
        image: ubuntu:latest
        ports:
          - name: http
            containerPort: 80
 _____________________________________________________________
        
      
 Single instance of Pod = Single Instance of Application
 
 Roles =
 Scheduler - where pod needs to be created
 API server - delegates the request to kubelet
 kubelet - creates the pod

________________________________________________________

Static pod
- aside to the automated pods created using yaml file we have to go to the pod and create the 

any .yml file seen in etc/kubernetesmanifest directory
we dont even need to apply the yml, it will pick in next 5 secs and start createing the pod.

pod created apends node name - podx-worker01 ##

___________________________________________________________

kubectl get pods -n kube-system -o wide

we cant delete a static pod.. if we delete...yaml file will create it again. the only way to remove is to remove the yaml file.

----

source code based deployments - we can plan a migration path to kubeadmn based cluster.
---

What are controllers in Kubernetes?
In Kubernetes, controllers are control loops that watch the state of your cluster, then make or request changes where needed. Each controller tries to move the current cluster state closer to the desired state

controlling a group of PODS

Types-
1) ReplicaSetup (Replication Controller)
2) DaemonSet
3) Deployment
4) Job
5) CronJob
6) Stateful
-----------

1) ReplicaSetup (Replication Controller)
____==================================================================================================
apiVersion: apps/v1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
kind: ReplicaSet <<<<<<<<<<<<<<<<<<<<<<<<<
metadata:
  name: frontend
  namespace: default
  labels:
    app: guestbook
    tier: frontend
spec:
  # modify replicas according to your case
  replicas: 3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<3 replicas<<if we dont mention anything then creates 1 replica and maintains it.
  selector:
    matchLabels: <<<<<<<<<<<<<<<<<<<kubectl check the label<<<look for the pods in the cluster matching the label before creating
      run: nginxpod
  template:
    metadata:
      #name is not done kubernetes will generate the name
      labels:
        run: nginxpod #### if 4 pods are needed , I found above then we can create next 3 here with this.
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google_samples/gb-frontend:v3
____==================================================================================================
so per understanding it will match if pod is available matching the label then it will get adopted for use, rest shortfall will create pods as mentioned in the replicas

2) DaemonSetAPI

https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/

- Monitoring agent
- OCS
- Antivirus

daemonset - default setup is kube-proxy, AV, etc. multiple will lead to conflict.

3) Deployment

https://kubernetes.io/docs/concepts/workloads/controllers/deployment/

how to access application POD-ID:port, but it can only access one POD, but not accessible outside.

for accessing multi-pod app deployment - 




+++++++++++++++++++++++++++++++++++++++++++++++++++
Service
- clusterIP
load balancer


Spec:
 type: Clsuter IP: its acts as a internal virtual load balancer that can forward a request int a singgle/group of pods
 selector:
  app: mywebsite
ports: 
  app: mywebsite
  ports: 80
  ports
  
  ______________________________________________________________
  

myshop.com --> External LB >> cluster IP > Pod IP > container
means iptables will be updated based on the configuration what we did for the pods/containers automatically

okay means iptables service always be up and running , Thanks

-------

spec:
 type: LoadBalancer  (creates external and internal LB), if it has a handle of cloud providers like AWS Azure, then external can be made.
 
 -----
 
 diff way of creating kube cluster
 self managed / on prem cluster
 
 cloud managed cluster on cloud
 - PAAS (Platform as a service)
 
 EKS - AWS - elastic kubernetes service
 AKS - Azure - Azure Kubernetes service
 Google - GKE - Google kubernetes service
 --------
 
 container orchestration cluster
 
 Master - in case clound managed cluster, all the master instaces are managed by cloud only. we will never have access to login to mater
 Worker - you will be reponsible for managing worker nodes  -- GKE standard (we will manage)
            - multi-master is done automatically
            - 
            
        -  you can leave the worker node management to the cloud service provier (GKE AUTO-pilot)
 
 GKE setup shown for creating a GKE standard cluster...
 
 ---------
 FLOW DIAGRAM--
endpoint URL (DNS) -- External LB -- nodeIP: nodeport (any one node in the cluster ) -- clusterIP:Port --PodIP:ContainerPort (any one of the POD)


-------
deployement vs replicaset

deployment = replicaset + rolling update/rollback (it creates new pod with latest update and deletes old one, while maitaining the uptime as well)

Bring down the website & update the latest version.

no Downtime deployment

Deployment is an abstraction layer over replicaset.
example - 
https://github.com/lerndevops/educka/blob/master/3-controllers/deployments/deployment-ex3.yml 

parameters
-------------------------
- maxsurge - no. of pods - max no of new pods which can be added. = 2 .... v1(9) + v2(3) = 12
--------------------------
- minimum ready seconds - wait for 45 secs post V2 comes up from V1
--------------------------
- maxunavailable - 1
kubectl get deployment
AVAILAbLE=10 + 2 (aligns to this value as per above parameter) .. out of 12 minimum 11 should be avialble for us to continue otherwise deployment is halted.

v1(10) + v2(2) = 12
minreadySeconds=45
maxUnavailable : 1

v1(9) + v2(3) = 12
minreadySeconds=45
maxUnavailable : 1

v1(0) + v2(12) = 12
minreadySeconds=45
maxUnavailable : 1

---------------------------
deployment UNDO....
Revision
v1
v2 - <delete>
v3  - undo - kube will roll one step back in the revision history (delete)
v2 - <active> -(if we do undo again then this goes back to v3)
v3 - (active) ------v1-v2-v3

kubectl rollout undo deployment kubeservice --to-revision 1  ## with this we can do directly to a desired version outpout from kubectl rollout history deployment kubeserve
kubectl rollout history deployment kubeserve

----------

how many versions can be stored

revisionHistoryLimit: 10 # default 10, and can be configured no limit.
-------------------
Restricting the resources that a container can take CPU/RAM etc. Resource limit.
specs
  containers:
     - name :cont1
       image:nginx
     
     env:
      - name: JAVA_HOME
        value: /usr/in/java
      - name: DB_HOST
        value: "1.2.3.4"
       - name: DB_PORT
        value: "200"
      resources
        requests: ## min amount of resources (cpu/ram) guranteed for the cont from the host/worker where it run
         cpu: 20m  #1 core cpu on your server = 1000 milli cpus = 20m = 2% of 1 cpu core
         memory: 128M
        limits: ## max amount of resources (cpu/ram) a cont can take the host/worker where it run
          cpu: 40m
          memory: 256M
    

----------------------------------------
deploy this application..

https://raw.githubusercontent.com/lerndevops/microservices-demo/master/deploy/kubernetes/complete-demo.yaml

https://github.com/pankajmamtanis/microservices-demo/blob/master/internal-docs/design.md


